<!doctype html>
<html lang="en">
<head>
<title>Seeing in the Dark: Using Faster R-CNN for Species Identification with Thermal Imaging</title>
<meta property="og:title" content="Seeing in the Dark: Using Faster R-CNN for Species Identification with Thermal Imaging" />
<meta name="twitter:title" content="Seeing in the Dark: Using Faster R-CNN for Species Identification with Thermal Imaging" />
<meta name="description" content="Your project about your cool topic described right here." />
<meta property="og:description" content="Your project about your cool topic described right here." />
<meta name="twitter:description" content="Your project about your cool topic described right here." />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" /> 
<meta name="viewport" content="width=device-width,initial-scale=1" />
<!-- bootstrap for mobile-friendly layout -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css" integrity="sha384-xOolHFLEh07PJGoPkLv1IbcEPTNtaed2xpHsD9ESMhqIYd0nLMwNLD69Npy4HI+N" crossorigin="anonymous">
<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-Fy6S3B9q64WdZWQUiU+q4/2Lc9npb8tCaSX9FK7E8HnRr0Jz8D6OP9dO5Vg3Q9ct" crossorigin="anonymous"></script>
<link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,700" rel="stylesheet">
<link href="style.css" rel="stylesheet">

</head>
<body class="nd-docs">
<div class="nd-pageheader">
 <div class="container">
 <h1 class="lead">
 <nobr class="widenobr">Seeing in the Dark: Using Faster R-CNN for Species Identification with Thermal Imaging</nobr>
 </h1>
 </div>
</div><!-- end nd-pageheader -->

<!-- <div class="container">
<div class="row">
<div class="col justify-content-center text-center">
<h2>An Analysis of [papername]</h2>
<p>Describe the paper and the big question about it that interests you.</p> -->
</div>
</div>
<div class="row">
<div class="col">

 <h2>Section I: Introduction</h2>
 <p>In the field of wildlife conservation and research, accurately detecting animals in difficult environments is critical. Traditional methods often struggle in low-light conditions or dense vegetation. Thermal imaging offers a promising alternative, allowing researchers to observe animals at night or through camouflage. This project delves into the capabilities of Faster R-CNN object detection models for identifying specific animal species in thermal images. Building upon the model’s ability to achieve high accuracy and faster training time, we aim to assess Faster R-CNN's effectiveness in challenging scenarios where traditional methods fall short. By evaluating Faster R-CNN’s performance on datasets containing thermal images of animal species, we hope to gain valuable insights into the model's capabilities for real-world applications. This project will contribute to understanding the strengths and limitations of Faster R-CNN for real-world animal identification tasks.
</p>

 <h2>Section II: Review of Research Paper</h2>
 <p>Many object detection networks rely on region proposal algorithms to generate candidate regions and hypothesize object locations before classifying each proposal as a specific object or background. However, this process can create bottlenecks and run slowly, especially for real-time applications. The research paper, “Faster R-CNN: Towards real-time object detection with region proposal networks” describes a framework using a Region Proposal Network (RPN) to generate high-quality region proposals coupled with Fast R-CNN to significantly reduce the runtime of object detection networks.
 </p>

 <p>
 The RPN is a fully convolutional network operating on an entire image that predicts object bounding boxes and their likelihood of containing an object simultaneously. By sharing convolutional features extracted by the main detector network (i.e. VGG-16), the RPN can carry out proposal generation and object classification with greater efficiency. The RPN is merged with Fast R-CNN into a single neural network and training alternates betweens RPN and Fast R-CNN. During this process, the RPN proposes regions based on image features and can tell the Fast R-CNN where to look to classify those proposals into specific objects or the background. Errors made by the Fast R-CNN are then fed back to the RPN during training, thus allowing for better proposal quality and detection accuracy. The entire architecture, named “Faster R-CNN”, allows for object detection and classification tasks with high accuracy and greater efficiency. In our project, we implement the Faster R-CNN model from the paper through Meta AI Research’s Detectron2 library, which includes state-of-the-art detection algorithms that provide the framework to allow us to train models such as Faster R-CNN. We aim to train Faster R-CNN models on datasets with varied types of images featuring different environments such as thermal images vs. normal images and identify different types of animals and compare their performance across datasets. Additionally, we would like to expand our investigations to explore how other models perform with these datasets as well.
 </p>

 <h2> Section III: Technical Structure </h2>
 
 <p>
 We began our framework by implementing the Dectron2 model, which is a sophisticated segmentation model that has a robust architecture and pretrained models provided by Facebook AI Research. After ensuring all dependencies and required libraries are correctly adjusted and installed on our notebook, we included a portion of the demo code provided by the Dectron2 team that showcases the magic this model does. The model is capable of predicting on various objects and annotates what they are in the input image.
 </p>

 <p>
 Next, we began to test if the model can be adapted to custom images. We found two datasets that are worth testing. The first dataset is a set of images of cheetahs captured in thermal cameras at night time. The second dataset is a set of images of people wearing masks at various occasions. The configurations of the model were adjusted, as well as the hyperparameters. After running on these two new datasets, the model is tested against the validation sets to evaluate its performance with the measuring metric of average precision. Then, the evaluation is carried out using the COCOEvaluator method, which reads through all the outputs and calculates the model’s effectiveness across all object predictions.
 </p>

 <p>
  Our entire implementation from setup to evaluation is well documented within our working google colab notebook, which can be accessed at <a href="https://colab.research.google.com/drive/13wVtFlOn9j4eAQCHSAC6yXSxlYSP7JXN#scrollTo=FsePPpwZSmqt">https://colab.research.google.com/drive/13wVtFlOn9j4eAQCHSAC6yXSxlYSP7JXN#scrollTo=FsePPpwZSmqt</a>.
 </p>

 <h2> Section IV: Experimental Findings </h2>


 <h4> Example of Faster R-CNN outputs when trained on normal images of aquariums: </h4>
 <img src="https://github.com/emily-ywang/RCNN_Classification_Project/raw/main/img/normal_raccoon_sample_1.png" alt="normal_raccoon_sample_1" style="width: 300px;">
 <img src="https://github.com/emily-ywang/RCNN_Classification_Project/raw/main/img/normal_raccoon_sample_2.png" alt="normal_raccoon_sample_2" style="width: 300px;">
 <img src="https://github.com/emily-ywang/RCNN_Classification_Project/raw/main/img/normal_raccoon_sample_3.png" alt="normal_raccoon_sample_3" style="width: 300px;">
 <img src="https://github.com/emily-ywang/RCNN_Classification_Project/raw/main/img/normal_raccoon_sample_4.png" alt="normal_raccoon_sample_4" style="width: 300px;">
 <p>DESCRIBE THE SAMPLE PICTURES.</p>

 <img src="https://github.com/emily-ywang/RCNN_Classification_Project/raw/main/img/normal_raccoon_total_loss.png" alt="normal_raccoon_total_loss" style="width: 400px;">
 <p> DESCRIBE THE TOTAL LOSS </p>

 <img src="https://github.com/emily-ywang/RCNN_Classification_Project/raw/main/img/normal_raccoon_cls_accuracy.png" alt="normal_raccoon_cls_accuracy" style="width: 400px;">
 <img src="https://github.com/emily-ywang/RCNN_Classification_Project/raw/main/img/normal_raccoon_false_negative.png" alt="normal_raccoon_false_negative"style="width: 400px;">
 <p> DESCRIBE THE ACCURACY DIAGRAMS </p>

 <img src="https://github.com/emily-ywang/RCNN_Classification_Project/raw/main/img/normal_raccoon_ap_scores.png" alt="normal_raccoon_ap_scores" style="width: 900px;">
 <p> DESCRIBE THE AP RESULTS</p>



 <h4> Example of Faster R-CNN outputs when trained on thermal images of cheetahs: </h4>
 <img src="https://github.com/emily-ywang/RCNN_Classification_Project/raw/main/img/thermal_cheetah_sample_1.png" alt="thermal_cheetah_sample_1" style="width: 300px;">
 <img src="https://github.com/emily-ywang/RCNN_Classification_Project/raw/main/img/thermal_cheetah_sample_2.png" alt="thermal_cheetah_sample_2" style="width: 300px;">
 <img src="https://github.com/emily-ywang/RCNN_Classification_Project/raw/main/img/thermal_cheetah_sample_3.png" alt="thermal_cheetah_sample_3" style="width: 300px;">
 <img src="https://github.com/emily-ywang/RCNN_Classification_Project/raw/main/img/thermal_cheetah_sample_4.png" alt="thermal_cheetah_sample_4" style="width: 300px;">
 <p> When trained with thermal images of cheetahs, Faster R-CNN effectively identifies single or multiple cheetahs within an image, even if they are far in the background. The images above show the effectiveness of the model identifying cheetahs with 97-99% confidence in thermal images depicting obscure monochromatic environments. This dataset is likely easier on the model than the thermal dogs dataset since there are no humans within the scenes to cause false positives.</p>

 <img src="https://github.com/emily-ywang/RCNN_Classification_Project/raw/main/img/thermal_cheetah_total_loss.png" alt="thermal_cheetah_total_loss" style="width: 400px;">
 <p> The cheetah classification challenge showed an almost linear decrease in the training loss across 300 training iterations of batch size 2, resulting in a final loss value of 0.26. Although it’s likely based on these graphs that better performance can be achieved through more iterations, we aimed to standardize and benchmark model performance. </p>

 <img src="https://github.com/emily-ywang/RCNN_Classification_Project/raw/main/img/thermal_cheetah_cls_accuracy.png" alt="thermal_cheetah_cls_accuracy" style="width: 400px;">
 <img src="https://github.com/emily-ywang/RCNN_Classification_Project/raw/main/img/thermal_cheetah_false_negative.png" alt="thermal_cheetah_false_negative"style="width: 400px;">
 <p> The classification accuracy of the cheetah classification model followed logarithmic growth in its performance, leveling out at 98% accuracy in correctly detecting a cheetah in a thermal image. A notable exception to this is a dip in steps 25 - 125; This alongside the false negative chart suggests that as the model begins to generalize and underfit the data, there is a period in training where it misses instances of cheetahs. </p>

 <img src="https://github.com/emily-ywang/RCNN_Classification_Project/raw/main/img/thermal_cheetah_ap_scores.png" alt="thermal_cheetah_ap_scores" style="width: 900px;">
 <p> In our results, the cheetah detection achieved an average precision (AP) score of 29.639, indicating a relatively mediocre level of accuracy in detecting cheetahs across different objects. The AP50 score measures precision at a 50 percent intersection over union threshold, and is high at 40.119, which means a strong performance in detection. Similarly, AP75 score represents the precision level at 75 percent intersection of union threshold, and stood at 35.051, which means a consistent accuracy even under stricter box matching conditions. However, APs, which is the average precision for smaller objects is 0, which means that the model is not performing very well when the cheetahs are very small in the image. Despite this, the model was able to get a APm score of 26.954, which is for the medium sized cheetahs, which is a promising performance. Furthermore, the metric of API is the average precision across all size objects is 68.653, which gives a high and stable overview of the model’s detection capability.</p>

 
 <h4> Example of Faster R-CNN outputs when trained on thermal images of dogs: </h4>
 <img src="https://github.com/emily-ywang/RCNN_Classification_Project/raw/main/img/thermal_dogs_sample_image_1.png" alt="thermal_dogs_sample_image_1" style="width: 300px;">
 <img src="https://github.com/emily-ywang/RCNN_Classification_Project/raw/main/img/thermal_dogs_sample_image_2.png" alt="thermal_dogs_sample_image_2" style="width: 300px;">
 <img src="https://github.com/emily-ywang/RCNN_Classification_Project/raw/main/img/thermal_dogs_sample_image_3.png" alt="thermal_dogs_sample_image_3" style="width: 300px;">
 <img src="https://github.com/emily-ywang/RCNN_Classification_Project/raw/main/img/thermal_dogs_sample_image_4.png" alt="thermal_dogs_sample_image_4" style="width: 300px;">
 <p> From an exploratory view of image classification outputs, we can see that the model is successfully identifying dogs in thermal imaging. This remains true even if it's a dog at a distance, and it does not seem to get confused with background items. However, it does generate false positives if a human is prevalent enough in the foreground.
</p>

 <img src="https://github.com/emily-ywang/RCNN_Classification_Project/raw/main/img/thermal_dogs_classification_total_loss.png" alt="thermal_dogs_classification_total_loss" style="width: 400px;">
 <p> The thermal dogs dataset went through a similar almost linear decrease in loss, with additional steepness between steps 0 - 75. This loss ended up at a value of 0.16 likely with opportunity for additional increase with more training.
</p>

 <img src="https://github.com/emily-ywang/RCNN_Classification_Project/raw/main/img/thermal_dogs_classification_cls_accuracy.png" alt="thermal_dogs_classification_cls_accuracy" style="width: 400px;">
 <img src="https://github.com/emily-ywang/RCNN_Classification_Project/raw/main/img/thermal_dogs_classification_false_negative.png" alt="thermal_dogs_classification_false_negative" style="width: 400px;">
 <p> The classification accuracy of the thermal dogs model followed logarithmic growth in its performance, leveling out at 98% accuracy in correctly detecting a dog in a thermal image. While this model shares a similar increase in the false negatives curve, it experiences a smoother increase in accuracy over time compared to the cheetah classification model.
</p>

 <img src="https://github.com/emily-ywang/RCNN_Classification_Project/raw/main/img/thermal_dogs_classification_ap_scores.png" alt="thermal_dogs_classification_ap_scores" style="width: 900px;">
 <p> Our results of the thermal dog detection achieved an average precision (AP) score of 41.714, indicating a relatively high level of accuracy in detecting dogs across different objects. The AP50 score measures precision at a 50 percent intersection over union threshold, and is high at 49.47, which means a strong performance in detection. Similarly, AP75 score represents the precision level at 75 percent intersection of union threshold, also at 49.74. However, APs, which is the average precision for smaller objects is 0, which means that the model is not performing very well when the dogs are very small in the image. Nevertheless, when dogs are medium sized, our model was able to achieve an APm score of 31.827, which is not bad for detecting medium sized objects. Furthermore, the metric of API is the average precision across all size objects is 43.045, which gives a comprehensive overview of the model’s detection capability.
</p>

 <h4> Model Result Comparison: </h4>
 <img src="https://github.com/emily-ywang/RCNN_Classification_Project/raw/main/img/ap_score_comparison_bar_chart.png" alt="ap_score_comparison_bar_chart" style="width: 900px;">
 <p> After we have trained and tested the model on both the cheetah and dog datasets, we combined their average precision metrics into the above bar chart for easier comparison. It is interesting to see that the model performs well in detecting cheetahs and thermal dogs, with higher scores in certain categories. The AP for dogs is significantly higher than for cheetahs, which suggests that the model has stronger capability in recognizing dogs over cheetahs. However, the API metric for cheetahs out performs that for dogs. This could mean that the model was able to train and study a wide range of cheetahs postures and images that helped the model learn to identify cheetahs better. 
 </p>
 

 <h4> Example of Faster R-CNN outputs when trained on normal images of raccoons: </h4>
 <img src="https://github.com/emily-ywang/RCNN_Classification_Project/raw/main/img/normal_aquarium_sample_1.png" alt="normal_aquarium_sample_1" style="width: 300px;">
 <img src="https://github.com/emily-ywang/RCNN_Classification_Project/raw/main/img/normal_aquarium_sample_2.png" alt="normal_aquarium_sample_2" style="width: 300px;">
 <img src="https://github.com/emily-ywang/RCNN_Classification_Project/raw/main/img/normal_aquarium_sample_3.png" alt="normal_aquarium_sample_3" style="width: 300px;">
 <img src="https://github.com/emily-ywang/RCNN_Classification_Project/raw/main/img/normal_aquarium_sample_4.png" alt="normal_aquarium_sample_4" style="width: 300px;">
 <p>DESCRIBE THE SAMPLE PICTURES.</p>

 <img src="https://github.com/emily-ywang/RCNN_Classification_Project/raw/main/img/normal_aquarium_total_loss.png" alt="normal_aquarium_total_loss" style="width: 400px;">
 <p> DESCRIBE THE TOTAL LOSS </p>

 <img src="https://github.com/emily-ywang/RCNN_Classification_Project/raw/main/img/normal_aquarium_cls_accuracy.png" alt="normal_aquarium_cls_accuracy" style="width: 400px;">
 <img src="https://github.com/emily-ywang/RCNN_Classification_Project/raw/main/img/normal_aquarium_false_negative.png" alt="normal_aquarium_false_negative"style="width: 400px;">
 <p> DESCRIBE THE ACCURACY DIAGRAMS </p>

 <img src="https://github.com/emily-ywang/RCNN_Classification_Project/raw/main/img/normal_aquarium_ap_scores.png" alt="normal_aquarium_ap_scores" style="width: 900px;">
 <p> DESCRIBE THE AP RESULTS</p>


 <h2> Section V: Conclusions </h2>

 <p>The Faster R-CNN object detection models are able to accurately locate and identify animals within thermal images of natural environments. The API scores of 45% and 80% suggest the cheetah identification model having strong identification capabilities in the foreground and the thermal dogs identification model having relatively weaker identification. However, animals at a distance display a far more conservative APm score at around 30% for both models. This is very promising as competitive multiclass image segmentation models on COCO datasets aim to hover at mean AP scores of 50% across classes. Although the steady decrease in loss suggests that the models can be improved with further training, this benchmark demonstrates a compact, realistic, and effective approach at animal classification within thermal images using Faster R-CNN models. In the future, we hope to expand this work into multi-breed classification with larger models. 
 </p>

 <p>
 Utilizing object detection models to identify animals across various image types has the potential to revolutionize various fields. To aid with wildlife conservation efforts, this pipeline could enable automated monitoring of wildlife populations in both day and night (i.e. thermal images), providing crucial data for protecting endangered species. Detecting animals in restricted areas could also be used to deter poachers. This system could even be used to minimize human-wildlife conflicts by detecting animals approaching livestock or human settlements in rural areas, allowing for preventative measures.  Furthermore, this implementation could help further research on animal behavior by allowing scientists to gain insights into nocturnal activities, hunting strategies, and animal interactions that were previously difficult to observe, especially during peak activity periods, which often occur at night. Overall, this project holds significant promise for wildlife conservation, agriculture, and research, offering a novel approach to understanding and interacting with wildlife.
 </p>
 
<div class="bibliography">
  <h2>Bibliography</h2>
  <div class="citation">
    Diana, Alessia, et al. "<span class="citation-title">A Systematic Review of the Use of Technology to Monitor Welfare in Zoo Animals: Is There Space for Improvement?</span>" <em>Animals</em>, vol. 11, no. 11, 25 Oct. 2021, p. 3048, <a href="https://www.mdpi.com/2076-2615/11/11/3048">www.mdpi.com/2076-2615/11/11/3048</a>, <a href="https://doi.org/10.3390/ani11113048">https://doi.org/10.3390/ani11113048</a>. <span class="access-date">Accessed 12 Apr. 2024.</span>
  </div>

  <div class="citation">
    Gandhi, Rohith. "<span class="citation-title">R-CNN, Fast R-CNN, Faster R-CNN, YOLO — Object Detection Algorithms.</span>" <em>Towards Data Science</em>, Towards Data Science, 9 July 2018, <a href="https://towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e">towardsdatascience.com/r-cnn-fast-r-cnn-faster-r-cnn-yolo-object-detection-algorithms-36d53571365e</a>. <span class="access-date">Accessed 12 Apr. 2024.</span>
  </div>

  <div class="citation">
    Ren, Shaoqing, et al. "<span class="citation-title">Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks.</span>" arXiv.org, 4 June 2015, <a href="https://arxiv.org/abs/1506.01497">arxiv.org/abs/1506.01497</a>. <span class="access-date">Accessed 12 Apr. 2024.</span> <br>
   
  </div>

  <div class="citation">
    Yuxin Wu, Alexander Kirillov, Francisco Massa, Wan-Yen Lo, Ross Girshick. "<span class="citation-title">Detectron2.</span>" (2019). <br>
  </div>

  <div class="citation"> 
     <a href="https://arxiv.org/abs/1506.01497">Hyperlink to Faster R-CNN paper</a>.
  </div>

  <div class="citation"> 
     <a href="https://github.com/facebookresearch/detectron2">Hyperlink to Detectron2 Github repository</a>.
  </div>
</div>
<div class="team_members">
  <h2>Team Members</h2>
  <h5>Team Members: Emily Wang, Marco Tortolani, Teng Li
</div>                                               


  
</div><!--col-->
</div><!--row -->
</div> <!-- container -->

<footer class="nd-pagefooter">
  <div class="row">
    <div class="col-6 col-md text-center">
      <a href="https://cs7150.baulab.info/">About DS 4440</a>
    </div>
  </div>
</footer>

</body>
<script>
$(document).on('click', '.clickselect', function(ev) {
  var range = document.createRange();
  range.selectNodeContents(this);
  var sel = window.getSelection();
  sel.removeAllRanges();
  sel.addRange(range);
});
// Google analytics below.
window.dataLayer = window.dataLayer || [];
</script>
</html>
